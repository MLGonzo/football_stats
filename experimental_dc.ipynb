{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "813fbcd5-a6e0-42e4-874b-1b129f6184a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson,skellam\n",
    "from scipy.optimize import minimize\n",
    "from bettools import get_data, generate_seasons, calculate_poisson_match_outcomes, calculate_ev_from_odds\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "\n",
    "# Suppress RuntimeWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "203bda94-1338-49e3-9c49-d403ca110a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    if x==0 and y==0:\n",
    "        return 1- (lambda_x * mu_y * rho)\n",
    "    elif x==0 and y==1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x==1 and y==0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x==1 and y==1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "    return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "            np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9553e251-1ec9-4eec-9b13-d299703558bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_parameters(dataset, debug = False, init_vals=None, options={'disp': True, 'maxiter':100},\n",
    "                     constraints = [{'type':'eq', 'fun': lambda x: sum(x[:20])-20}] , **kwargs):\n",
    "    teams = np.sort(dataset['HomeTeam'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['AwayTeam'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1,(n_teams)), # attack strength\n",
    "                                      np.random.uniform(0,-1,(n_teams)), # defence strength\n",
    "                                      np.array([0, 1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                     ))\n",
    "    def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "        lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "        return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "                np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "    def estimate_paramters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams:(2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        log_like = [dc_log_like(row.FTHG, row.FTAG, score_coefs[row.HomeTeam], defend_coefs[row.HomeTeam],\n",
    "                     score_coefs[row.AwayTeam], defend_coefs[row.AwayTeam], rho, gamma) for row in dataset.itertuples()]\n",
    "        return -sum(log_like)\n",
    "    opt_output = minimize(estimate_paramters, init_vals, options=options, constraints = constraints, **kwargs)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                        opt_output.x)) \n",
    "\n",
    "# season_list = generate_seasons(2017, 2018)\n",
    "\n",
    "# df_ls = get_data(season_list, leagues, additional_cols=['HS','AS','FTR'])\n",
    "\n",
    "# dc_df = pd.concat(df_ls)\n",
    "\n",
    "# params = solve_parameters(dc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ac8e84ad-0d9d-4c2c-9ce5-2a974dd13e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_means(param_dict, homeTeam, awayTeam):\n",
    "    return [np.exp(param_dict['attack_'+homeTeam] + param_dict['defence_'+awayTeam] + param_dict['home_adv']),\n",
    "            np.exp(param_dict['defence_'+homeTeam] + param_dict['attack_'+awayTeam])]\n",
    "\n",
    "def dixon_coles_simulate_match(params_dict, homeTeam, awayTeam, max_goals=10):\n",
    "    team_avgs = calc_means(params_dict, homeTeam, awayTeam)\n",
    "    team_pred = [[poisson.pmf(i, team_avg) for i in range(0, max_goals+1)] for team_avg in team_avgs]\n",
    "    output_matrix = np.outer(np.array(team_pred[0]), np.array(team_pred[1]))\n",
    "    correction_matrix = np.array([[rho_correction(home_goals, away_goals, team_avgs[0],\n",
    "                                                   team_avgs[1], params['rho']) for away_goals in range(2)]\n",
    "                                   for home_goals in range(2)])\n",
    "    output_matrix[:2,:2] = output_matrix[:2,:2] * correction_matrix\n",
    "    return output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffc5bb-71a9-4dd1-b249-8b7f1227f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ars_lut_dc = dixon_coles_simulate_match(params, 'Arsenal', 'Luton', max_goals=10)\n",
    "\n",
    "home_win = list(map(lambda x:np.sum(np.tril(x, -1)), [ars_lut_dc]))[0]\n",
    "draw_win = list(map(lambda x:np.sum(np.diag(x)), [ars_lut_dc]))[0]\n",
    "away_win = list(map(lambda x:np.sum(np.triu(x, 1)), [ars_lut_dc]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db6b042f-0ed5-4d4a-b90a-f20779aeb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc_log_like_decay(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma, t, xi=0):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "    return  np.exp(-xi*t) * (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "                              np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c48614d-4c05-489b-9053-c9b0ffe9860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_parameters_decay(dataset, xi=0.001, debug = False, init_vals=None, options={'disp': True, 'maxiter':100},\n",
    "                     constraints = [{'type':'eq', 'fun': lambda x: sum(x[:20])-20}] , **kwargs):\n",
    "    teams = np.sort(dataset['HomeTeam'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['AwayTeam'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"something not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1,(n_teams)), # attack strength\n",
    "                                      np.random.uniform(0,-1,(n_teams)), # defence strength\n",
    "                                      np.array([0,1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                     ))\n",
    "        \n",
    "    def dc_log_like_decay(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma, t, xi=xi):\n",
    "        lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "        return  np.exp(-xi*t) * (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "                                  np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "    def estimate_paramters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams:(2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        log_like = [dc_log_like_decay(row.FTHG, row.FTAG, score_coefs[row.HomeTeam], defend_coefs[row.HomeTeam],\n",
    "                                      score_coefs[row.AwayTeam], defend_coefs[row.AwayTeam], \n",
    "                                      rho, gamma, row.time_diff, xi=xi) for row in dataset.itertuples()]\n",
    "        return -sum(log_like)\n",
    "    opt_output = minimize(estimate_paramters, init_vals, options=options, constraints = constraints)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                        opt_output.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb96a057-326b-43c5-a0b7-0cd3598cef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1x2_probs(match_score_matrix):\n",
    "    return dict({\"H\":np.sum(np.tril(match_score_matrix, -1)), \n",
    "                 \"A\":np.sum(np.triu(match_score_matrix, 1)), \"D\":np.sum(np.diag(match_score_matrix))})\n",
    "\n",
    "def build_temp_model(dataset, time_diff, xi=0.000, init_params=None):\n",
    "    test_dataset = dataset[((dataset['time_diff']<=time_diff) & (dataset['time_diff']>=(time_diff-2)))]\n",
    "    if len(test_dataset)==0:\n",
    "        return 0\n",
    "    train_dataset = dataset[dataset['time_diff']>time_diff]\n",
    "    train_dataset['time_diff'] = train_dataset['time_diff'] - time_diff\n",
    "    params = solve_parameters_decay(train_dataset, xi=xi, init_vals=init_params)\n",
    "    predictive_score = sum([np.log(get_1x2_probs(dixon_coles_simulate_match(\n",
    "                    params, row.HomeTeam, row.AwayTeam))[row.FTR]) for row in test_dataset.itertuples()])\n",
    "    return predictive_score    \n",
    "\n",
    "def get_total_score_xi(xi):\n",
    "    xi_result = [build_temp_model(dc_df, day, xi=xi) for day in range(99,-1,-3)]\n",
    "    with open('find_xi_1season_{}.txt'.format(str(xi)[2:]), 'wb') as thefile:\n",
    "        pickle.dump(xi_result, thefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d34bdfa-136b-4de9-87be-29ce37502a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly_criterion(probability, odds, bankroll, kelly_fraction=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the optimal betting amount using the Kelly Criterion, with an option to use a fraction of the full recommendation.\n",
    "    \n",
    "    Parameters:\n",
    "    - probability: The probability of the outcome occurring.\n",
    "    - odds: The decimal odds offered for the bet.\n",
    "    - bankroll: The current amount in your bankroll.\n",
    "    - kelly_fraction: Fraction of the Kelly bet to use (default is 1.0 for 100%).\n",
    "    \n",
    "    Returns:\n",
    "    - The optimal amount to bet from your bankroll, adjusted by the specified Kelly fraction.\n",
    "    \"\"\"\n",
    "    b = odds - 1  # Convert decimal odds to b in the formula\n",
    "    q = 1 - probability  # Probability of losing\n",
    "    \n",
    "    # Calculate the fraction of the bankroll to bet, according to the Kelly Criterion\n",
    "    f_star = (b * probability - q) / b\n",
    "    \n",
    "    # Adjust the fraction with the specified Kelly fraction\n",
    "    f_star = max(f_star, 0) * kelly_fraction\n",
    "    \n",
    "    # Calculate the amount to bet\n",
    "    bet_amount = f_star * bankroll\n",
    "    \n",
    "    return bet_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2496f880-10e3-4994-b17e-0b8175afc8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = ['E0']\n",
    "\n",
    "season_list = generate_seasons(2014, 2024)\n",
    "\n",
    "df_ls = get_data(season_list, leagues, additional_cols=['HS','AS','FTR'])\n",
    "\n",
    "main_df = pd.concat(df_ls)\n",
    "\n",
    "main_df = main_df[-500:]\n",
    "\n",
    "main_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "main_df['Date'] = pd.to_datetime(main_df['Date'],  format='%d/%m/%y')\n",
    "main_df['time_diff'] = (max(main_df['Date']) - main_df['Date']).dt.days\n",
    "main_df = main_df[['HomeTeam','AwayTeam','FTHG','FTAG', 'FTR', 'time_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31233f9f-7f9e-489f-a71c-30620ae34b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 825.3474170622521\n",
      "            Iterations: 53\n",
      "            Function evaluations: 2672\n",
      "            Gradient evaluations: 53\n"
     ]
    }
   ],
   "source": [
    "params = solve_parameters_decay(main_df, xi=0.00325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d2bb8083-06dd-49ee-9db9-c5fedff52ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Away', 0.18325254664701998)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_betting_prediction(home_odds, draw_odds, away_odds, params, home_team, away_team, bankroll):\n",
    "    predicted_probs = get_1x2_probs(dixon_coles_simulate_match(params, home_team, away_team, max_goals=10))\n",
    "    \n",
    "    home_ev = calculate_ev_from_odds(home_odds, predicted_probs['H'])\n",
    "    away_ev = calculate_ev_from_odds(away_odds, predicted_probs['A'])\n",
    "    draw_ev = calculate_ev_from_odds(draw_odds, predicted_probs['D'])\n",
    "\n",
    "    max_ev = max([home_ev, away_ev, draw_ev])\n",
    "    if max_ev == home_ev:\n",
    "        bet_amount = kelly_criterion(predicted_probs['H'], home_odds, bankroll, kelly_fraction=0.05)\n",
    "        bet_selection = 'Home'\n",
    "    if max_ev == away_ev:\n",
    "        bet_amount = kelly_criterion(predicted_probs['A'], away_odds, bankroll, kelly_fraction=0.05)\n",
    "        bet_selection = 'Away'\n",
    "    elif max_ev == draw_ev:\n",
    "        bet_amount = kelly_criterion(predicted_probs['D'], draw_odds, bankroll, kelly_fraction=0.05)\n",
    "        bet_selection = 'Draw'\n",
    "    return bet_selection, bet_amount\n",
    "\n",
    "make_betting_prediction(1.68, 4.23, 4.5, params, \"Chelsea\", 'Everton', 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0de9e52b-d66c-458d-b1dd-20f5fe32dc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_Birmingham': 0.8050523897496342,\n",
       " 'attack_Blackburn': 1.0021238194010662,\n",
       " 'attack_Bristol City': 0.9391071205764208,\n",
       " 'attack_Cardiff': 0.813067093406044,\n",
       " 'attack_Coventry': 1.2662105726498234,\n",
       " 'attack_Huddersfield': 0.8715634067129769,\n",
       " 'attack_Hull': 1.1040636762199296,\n",
       " 'attack_Ipswich': 1.4388374074475823,\n",
       " 'attack_Leeds': 1.336719158971619,\n",
       " 'attack_Leicester': 1.3932487453042963,\n",
       " 'attack_Middlesbrough': 1.090096797825093,\n",
       " 'attack_Millwall': 0.6472968191795301,\n",
       " 'attack_Norwich': 1.3401056517176584,\n",
       " 'attack_Plymouth': 0.9978687909828998,\n",
       " 'attack_Preston': 1.0563956507299663,\n",
       " 'attack_QPR': 0.7085882861220348,\n",
       " 'attack_Rotherham': 0.44121515083825785,\n",
       " 'attack_Sheffield Weds': 0.6232189651769978,\n",
       " 'attack_Southampton': 1.4202885049157383,\n",
       " 'attack_Stoke': 0.7049319920724367,\n",
       " 'attack_Sunderland': 0.876893436390103,\n",
       " 'attack_Swansea': 0.9620295779839108,\n",
       " 'attack_Watford': 1.0249526479642235,\n",
       " 'attack_West Brom': 1.1990549614542747,\n",
       " 'defence_Birmingham': -0.720131894840467,\n",
       " 'defence_Blackburn': -0.6195333554140177,\n",
       " 'defence_Bristol City': -1.1152033321673818,\n",
       " 'defence_Cardiff': -0.8469639233480771,\n",
       " 'defence_Coventry': -0.9449604779661736,\n",
       " 'defence_Huddersfield': -0.6422639477596491,\n",
       " 'defence_Hull': -0.8322942094465933,\n",
       " 'defence_Ipswich': -0.9209024713643562,\n",
       " 'defence_Leeds': -1.4120531765237094,\n",
       " 'defence_Leicester': -1.1517606100243363,\n",
       " 'defence_Middlesbrough': -0.9076897497483271,\n",
       " 'defence_Millwall': -0.9223014647857117,\n",
       " 'defence_Norwich': -0.8267529006018176,\n",
       " 'defence_Plymouth': -0.7120076211298951,\n",
       " 'defence_Preston': -0.850807024920694,\n",
       " 'defence_QPR': -0.9234897829419373,\n",
       " 'defence_Rotherham': -0.48375352036497493,\n",
       " 'defence_Sheffield Weds': -0.7209522367708835,\n",
       " 'defence_Southampton': -0.8683578452347586,\n",
       " 'defence_Stoke': -0.7960167329625811,\n",
       " 'defence_Sunderland': -0.9718374948028197,\n",
       " 'defence_Swansea': -0.7768947463453878,\n",
       " 'defence_Watford': -0.8782794547256446,\n",
       " 'defence_West Brom': -1.16067282778774,\n",
       " 'rho': 0.014197945272182308,\n",
       " 'home_adv': 0.19910189678277737}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5e3e5-6c18-4b41-9d10-dfb7bf3f288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leagues = ['E0']\n",
    "\n",
    "season_list = generate_seasons(2014, 2024)\n",
    "\n",
    "df_ls = get_data(season_list, leagues)\n",
    "\n",
    "main_df = pd.concat(df_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6de05a-eb32-4766-9e51-4641bbcf162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['Date'] = pd.to_datetime(main_df['Date'])\n",
    "main_df = main_df.sort_values('Date')\n",
    "main_df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbca2c1-8f36-400c-b3c1-98c8048221a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def walk_forward_validation(data, initial_train_size, test_size, num_iterations):\n",
    "    total_rows = len(data)\n",
    "    \n",
    "    train_start = 0\n",
    "    train_end = initial_train_size\n",
    "    test_end = train_end + test_size\n",
    "    \n",
    "    results = []\n",
    "    iteration = 0  # To track the number of iterations\n",
    "    while test_end <= total_rows and iteration < num_iterations:\n",
    "        # Splitting the data\n",
    "        train_data = data.iloc[train_start:train_end]\n",
    "        test_data = data.iloc[train_end:test_end]\n",
    "\n",
    "        # Calculating time difference from the end of the training set\n",
    "        max_train_date = train_data.index.max()\n",
    "        train_data['time_diff'] = (max_train_date - train_data.index).days\n",
    "\n",
    "        # Selecting columns (adjust as necessary)\n",
    "        train_data = train_data[['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'time_diff']]\n",
    "\n",
    "        successful_fit = False\n",
    "        attempts = 0\n",
    "        while not successful_fit and attempts < 5:  # Try fitting parameters up to 2 times\n",
    "            try:\n",
    "                params = solve_parameters_decay(train_data, xi=0.00325)\n",
    "                # Insert your prediction and evaluation logic here, using `params`\n",
    "                # For each row in test_data, calculate predictions and append to test_data\n",
    "                test_data = test_data.reset_index()\n",
    "                for i in range(len(test_data)):\n",
    "                    home_team = test_data.loc[i]['HomeTeam']\n",
    "                    away_team = test_data.loc[i]['AwayTeam']\n",
    "                    probs_1x2 = get_1x2_probs(dixon_coles_simulate_match(params, home_team, away_team, max_goals=10))\n",
    "                    test_data.loc[i, 'home_win_prob'] = probs_1x2['H']\n",
    "                    test_data.loc[i, 'away_win_prob'] = probs_1x2['A']\n",
    "                    test_data.loc[i, 'draw_win_prob'] = probs_1x2['D']\n",
    "                results.append(test_data)\n",
    "                successful_fit = True\n",
    "            except Exception as e:\n",
    "                # If parameter fitting fails, add more data to the training set and try again\n",
    "                print(f\"Parameter fitting failed on attempt {attempts + 1}: {e}. Trying with a larger training set.\")\n",
    "                train_end += test_size  # Expanding the training set window\n",
    "                if train_end + test_size > total_rows:\n",
    "                    print(\"Not enough data to expand the training set and perform another test. Stopping.\")\n",
    "                    return results\n",
    "                train_data = data.iloc[train_start:train_end]\n",
    "                train_data['time_diff'] = (max_train_date - train_data.index).days\n",
    "                train_data = train_data[['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'time_diff']]\n",
    "                attempts += 1\n",
    "        if successful_fit:\n",
    "            # Move the window forward\n",
    "            train_end = test_end\n",
    "            test_end += test_size\n",
    "            iteration += 1  # Increment the iteration count\n",
    "    return results\n",
    "\n",
    "res = walk_forward_validation(main_df, 500, 10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14bcc8-817b-4187-8bd5-2087411954fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
